{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c0688d",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Build a system that allows any company employee to consult, in natural language, information from the internal knowledge base (e.g., how the company's main model works, details about motorcycle couriers and services)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde33aac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8afd80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display\n",
    "import shutil\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory,ChatMessageHistory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ed16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a68b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4273a12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading Knowlege Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b450f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add metadata\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "# Adjusting utf-8 \n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "# Path to folder with the files\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "# Reading files\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=160)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e06d8b",
   "metadata": {},
   "source": [
    "# Vector Storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727650ce",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embeddings open source\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ecc1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9b6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete if already exists\n",
    "if os.path.exists(db_name):\n",
    "    shutil.rmtree(db_name)\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4613c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ab476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The vectors\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244f241",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualizing the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework \n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue', 'green', 'red', 'orange'][['model', 'motoboys', 'services', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"iframe_connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc86494",
   "metadata": {},
   "source": [
    "The figure visualizes the distribution of high-dimensional document embeddings in a 2D space using t-SNE. Each point represents a document, and its color indicates its category. Points that appear closer together are likely to be semantically similar, helping us identify clusters and relationships between categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b77aa",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ade613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"llama3.2\"\n",
    "MODEL = \"phi3\"\n",
    "\n",
    "# create a new Chat with llama3.2\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL, base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# set up the conversation memory for the chat, in case we want LLM to respond considering previous questions\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key=\"answer\")\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# putting it together: set up the conversation chain with the MODEL, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever,return_source_documents=True, output_key=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32c0d4-c514-4665-8cc7-01231ee21ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Let's try a simple question\n",
    "query = \"Please explain the System Flow for Demand Forecasting process in a couple of sentences\"\n",
    "result = conversation_chain.invoke({\"question\": query,\"chat_history\": []})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Let's try a simple question\n",
    "query = \"Please tell me Diego Fernandes key responsabilities, in English\"\n",
    "result = conversation_chain.invoke({\"question\": query,\"chat_history\": []})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad7234",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feedback Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48542b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackEntry(BaseModel):\n",
    "    timestamp: datetime = Field(default_factory=datetime.utcnow)\n",
    "    user_query: str\n",
    "    model_response: str\n",
    "    feedback: str\n",
    "    source_documents: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEEDBACK_LOG = Path(\"feedback_log.jsonl\")\n",
    "\n",
    "def save_feedback_async(entry: FeedbackEntry):\n",
    "    logging.info(\"Feedback Saved\")\n",
    "    def _save():\n",
    "        with FEEDBACK_LOG.open(\"a\") as f:\n",
    "            f.write(entry.model_dump_json() + \"\\n\")\n",
    "    Thread(target=_save).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_interaction = {\"query\": \"\", \"answer\": \"\", \"sources\": []}\n",
    "\n",
    "def generate_response(message, history):\n",
    "    result = conversation_chain({\"question\": message,\"chat_history\":[]})\n",
    "    answer = result[\"answer\"]\n",
    "    sources = [doc.page_content for doc in result[\"source_documents\"]]\n",
    "    \n",
    "    documents = result.get(\"source_documents\", [])\n",
    "    top_docs = documents[:2]\n",
    "    doc_names = []\n",
    "    for i, doc in enumerate(top_docs, 1):\n",
    "        source = doc.metadata.get(\"source\", f\"Documento {i}\")\n",
    "        filename = source.split(\"/\")[-1]\n",
    "        doc_names.append(f\"{i}. {filename}\")\n",
    "\n",
    "    rag_list = \"\\n\".join(doc_names)\n",
    "\n",
    "    last_interaction[\"query\"] = message\n",
    "    last_interaction[\"answer\"] = answer\n",
    "    last_interaction[\"sources\"] = sources\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    return \"\", history,rag_list\n",
    "\n",
    "def register_feedback(feedback_type):\n",
    "    entry = FeedbackEntry(\n",
    "        user_query=last_interaction[\"query\"],\n",
    "        model_response=last_interaction[\"answer\"],\n",
    "        feedback=feedback_type,\n",
    "        source_documents=last_interaction[\"sources\"]\n",
    "    )\n",
    "    save_feedback_async(entry)\n",
    "    return f\"Feedback '{feedback_type}' registered sucessfully.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aff509",
   "metadata": {},
   "source": [
    "# Chat Interface - Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2842a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Soimplest interface\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question,\"chat_history\": []})\n",
    "    return result[\"answer\"]\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More fancy user interface\n",
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"## üí¨ LLM Deliveries Internal Chat\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):  # Chat \n",
    "            chatbot = gr.Chatbot(type=\"messages\")\n",
    "\n",
    "            with gr.Row():  # Input + buttons\n",
    "                msg = gr.Textbox(placeholder=\"Type your question...\",  show_label=False, scale=9)\n",
    "                with gr.Column(scale=1, min_width=60):\n",
    "                    send_btn = gr.Button(\"‚û§\", size=\"sm\")\n",
    "\n",
    "        with gr.Column(scale=1): \n",
    "            gr.Markdown(\"### Feedback\")\n",
    "            thumbs_up = gr.Button(\"üëç (Good Answer)\")\n",
    "            thumbs_down = gr.Button(\"üëé (Bad Answer)\")\n",
    "            feedback_status = gr.Textbox(label=\"Feedback Status\")\n",
    "\n",
    "            gr.Markdown(\"### Relevant Documents\")\n",
    "            rag_docs = gr.Textbox(lines=6, interactive=False, label=None)\n",
    "\n",
    "    send_btn.click(generate_response, inputs=[msg, chatbot], outputs=[msg, chatbot, rag_docs])\n",
    "    msg.submit(generate_response, inputs=[msg, chatbot], outputs=[msg, chatbot, rag_docs])\n",
    "    thumbs_up.click(fn=lambda: register_feedback(\"thumbs_up\"), outputs=feedback_status)\n",
    "    thumbs_down.click(fn=lambda: register_feedback(\"thumbs_down\"), outputs=feedback_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f7061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b89a5",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading feedbacks\n",
    "df = pd.read_json(Path(\"feedback_log.jsonl\"), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating percentage of correct answers\n",
    "df[\"feedback_binario\"] = df[\"feedback\"].map({\"thumbs_up\": 1, \"thumbs_down\": 0})\n",
    "correct_answer_rate = df[\"feedback_binario\"].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a1b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e9dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
