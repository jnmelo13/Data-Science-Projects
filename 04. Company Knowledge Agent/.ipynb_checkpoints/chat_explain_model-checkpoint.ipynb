{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f04b94f-7b5c-4e44-a813-a418561d5ae0",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Build a system that allows any company employee to consult, in natural language, information from the internal knowledge base (e.g., how the company's main model works, details about motorcycle couriers and services)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4422e-ee32-4107-8893-53a415b61806",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8339c139-f7a9-4f1d-b500-e6bb985d5a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display\n",
    "import shutil\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory,ChatMessageHistory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78851514-03ba-42fb-a7aa-55a8f5020744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5291b5-7e5a-4877-a204-d01e774f2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a721fe7-28dd-46b3-89ae-f81a15e443e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5011e6-afa9-40d6-a0ac-9279cd84d855",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading Knowlege Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7ba606-d504-4641-9136-98fc45d1f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add metadata\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "# Adjusting utf-8 \n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "# Path to folder with the files\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "# Reading files\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bfb06e-34eb-412a-b4c9-697c8ecb0a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1302, which is longer than the specified 800\n",
      "Created a chunk of size 1318, which is longer than the specified 800\n",
      "Created a chunk of size 1338, which is longer than the specified 800\n",
      "Created a chunk of size 890, which is longer than the specified 800\n",
      "Created a chunk of size 1009, which is longer than the specified 800\n",
      "Created a chunk of size 1225, which is longer than the specified 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 57\n",
      "Document types found: {'motoboys', 'model', 'company', 'services'}\n"
     ]
    }
   ],
   "source": [
    "# Creating chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=160)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97e1ff-dc7a-4706-8725-5dabb1e94c0d",
   "metadata": {},
   "source": [
    "# Vector Storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b028b9-5979-4d7f-a3f5-cb5245a66734",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 20:38:00.190397: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-20 20:38:00.193415: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-20 20:38:00.201200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753054680.217318   11396 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753054680.222104   11396 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753054680.235061   11396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753054680.235081   11396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753054680.235082   11396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753054680.235083   11396 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-20 20:38:00.239899: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Embeddings open source\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746a495a-5a30-4299-a0ae-8ebec5c15957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed8bfc89-9e59-476c-98da-ee095509bb42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete if already exists\n",
    "if os.path.exists(db_name):\n",
    "    shutil.rmtree(db_name)\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1052e84-d9a5-46f7-965e-a7dc02c7cd00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 57 documents\n"
     ]
    }
   ],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1bc03ba-51cc-4fab-855e-db6108d1b25c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 vectors with 384 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "# The vectors\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c303e9c-6535-4b41-b451-ef611160e738",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Visualizing the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694423e-dcc7-4bba-9d49-a6ad50d4b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework \n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue', 'green', 'red', 'orange'][['model', 'motoboys', 'services', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826b15a-fa70-4be3-9d44-68f69afa5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"iframe_connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b70c20-41e8-4bb9-9ea5-456846d744c4",
   "metadata": {},
   "source": [
    "The figure visualizes the distribution of high-dimensional document embeddings in a 2D space using t-SNE. Each point represents a document, and its color indicates its category. Points that appear closer together are likely to be semantically similar, helping us identify clusters and relationships between categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84322ef0-ec46-49b3-96b1-7ca0f6cc33ca",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c98ffbbd-4168-4c82-8b1b-0334ecd433ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"llama3.2\"\n",
    "MODEL = \"phi3\"\n",
    "\n",
    "# create a new Chat with llama3.2\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL, base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# set up the conversation memory for the chat, in case we want LLM to respond considering previous questions\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key=\"answer\")\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# putting it together: set up the conversation chain with the MODEL, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever,return_source_documents=True, output_key=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888520b9-abd8-4ddd-a35d-c274951bb37e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The demand forecast system uses historical sales data from various cities to predict future service slot needs. It employs SARIMA models, considering factors like order volume and seasonality, then identifies top markets while providing scheduling insights for planning purposes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.7 ms, sys: 564 µs, total: 95.2 ms\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's try a simple question\n",
    "query = \"Please explain the System Flow for Demand Forecasting process in a couple of sentences\"\n",
    "result = conversation_chain.invoke({\"question\": query,\"chat_history\": []})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c0b399-6657-4b48-9846-5ce4158b9518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Key Responsibilities of Diego Fernandes as a Delivery Driver at Correios:\n",
       "1. Deliver mail and packages to intended recipients ensuring accurate delivery.\n",
       "2. Complete necessary paperwork associated with each delivery promptly.\n",
       "3. Maintain an organized system for handling parcels, potentially contributing positively in the eyes of management based on past feedback regarding his attention to package organization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.5 ms, sys: 1.72 ms, total: 80.2 ms\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's try a simple question\n",
    "query = \"Please tell me Diego Fernandes key responsabilities, in English\"\n",
    "result = conversation_chain.invoke({\"question\": query,\"chat_history\": []})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0775c02-fac3-4167-88f9-23a78d1e618d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feedback Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0040a0c-849d-4ce5-a839-b9f5f99da0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackEntry(BaseModel):\n",
    "    timestamp: datetime = Field(default_factory=datetime.utcnow)\n",
    "    user_query: str\n",
    "    model_response: str\n",
    "    feedback: str\n",
    "    source_documents: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d730cb7d-871f-4f9b-80e5-a3a9fcb4b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEEDBACK_LOG = Path(\"feedback_log.jsonl\")\n",
    "\n",
    "def save_feedback_async(entry: FeedbackEntry):\n",
    "    logging.info(\"Feedback Saved\")\n",
    "    def _save():\n",
    "        with FEEDBACK_LOG.open(\"a\") as f:\n",
    "            f.write(entry.model_dump_json() + \"\\n\")\n",
    "    Thread(target=_save).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d27b3546-d486-4f03-8d4a-b2ce6b578a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_interaction = {\"query\": \"\", \"answer\": \"\", \"sources\": []}\n",
    "\n",
    "def generate_response(message, history):\n",
    "    result = conversation_chain({\"question\": message,\"chat_history\":[]})\n",
    "    answer = result[\"answer\"]\n",
    "    sources = [doc.page_content for doc in result[\"source_documents\"]]\n",
    "    \n",
    "    documents = result.get(\"source_documents\", [])\n",
    "    top_docs = documents[:2]\n",
    "    doc_names = []\n",
    "    for i, doc in enumerate(top_docs, 1):\n",
    "        source = doc.metadata.get(\"source\", f\"Documento {i}\")\n",
    "        filename = source.split(\"/\")[-1]\n",
    "        doc_names.append(f\"{i}. {filename}\")\n",
    "\n",
    "    rag_list = \"\\n\".join(doc_names)\n",
    "\n",
    "    last_interaction[\"query\"] = message\n",
    "    last_interaction[\"answer\"] = answer\n",
    "    last_interaction[\"sources\"] = sources\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    return \"\", history,rag_list\n",
    "\n",
    "def register_feedback(feedback_type):\n",
    "    entry = FeedbackEntry(\n",
    "        user_query=last_interaction[\"query\"],\n",
    "        model_response=last_interaction[\"answer\"],\n",
    "        feedback=feedback_type,\n",
    "        source_documents=last_interaction[\"sources\"]\n",
    "    )\n",
    "    save_feedback_async(entry)\n",
    "    return f\"Feedback '{feedback_type}' registered sucessfully.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469752d8-516b-4c29-a153-9dff7d95aa98",
   "metadata": {},
   "source": [
    "# Chat Interface - Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1fc278a-921a-4cbb-89d7-e471e59bbe10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Soimplest interface\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question,\"chat_history\": []})\n",
    "    return result[\"answer\"]\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c2195a1-2514-4e35-90c5-a282c6c2be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More fancy user interface\n",
    "with gr.Blocks() as ui:\n",
    "    gr.Markdown(\"## 💬 LLM Deliveries Internal Chat\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):  # Chat \n",
    "            chatbot = gr.Chatbot(type=\"messages\")\n",
    "\n",
    "            with gr.Row():  # Input + buttons\n",
    "                msg = gr.Textbox(placeholder=\"Type your question...\",  show_label=False, scale=9)\n",
    "                with gr.Column(scale=1, min_width=60):\n",
    "                    send_btn = gr.Button(\"➤\", size=\"sm\")\n",
    "\n",
    "        with gr.Column(scale=1): \n",
    "            gr.Markdown(\"### Feedback\")\n",
    "            thumbs_up = gr.Button(\"👍 (Good Answer)\")\n",
    "            thumbs_down = gr.Button(\"👎 (Bad Answer)\")\n",
    "            feedback_status = gr.Textbox(label=\"Feedback Status\")\n",
    "\n",
    "            gr.Markdown(\"### Relevant Documents\")\n",
    "            rag_docs = gr.Textbox(lines=6, interactive=False, label=None)\n",
    "\n",
    "    send_btn.click(generate_response, inputs=[msg, chatbot], outputs=[msg, chatbot, rag_docs])\n",
    "    msg.submit(generate_response, inputs=[msg, chatbot], outputs=[msg, chatbot, rag_docs])\n",
    "    thumbs_up.click(fn=lambda: register_feedback(\"thumbs_up\"), outputs=feedback_status)\n",
    "    thumbs_down.click(fn=lambda: register_feedback(\"thumbs_down\"), outputs=feedback_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "073e08b3-c7d7-497f-9813-673d680db8b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d4f8fb-e15a-49f0-984b-d5a2d5c1d1b2",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae2436cb-1846-493f-b5c8-3519d1b6af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca035652-310d-4f45-8fca-e8349b5ce982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading feedbacks\n",
    "df = pd.read_json(Path(\"feedback_log.jsonl\"), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "637b3358-091e-4292-8901-d528bfb0578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating percentage of correct answers\n",
    "df[\"feedback_binario\"] = df[\"feedback\"].map({\"thumbs_up\": 1, \"thumbs_down\": 0})\n",
    "correct_answer_rate = df[\"feedback_binario\"].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d08d9-5644-47ee-86cb-a66670b1882a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efbd7a-520c-4c8f-b2df-3b53aac6776b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
